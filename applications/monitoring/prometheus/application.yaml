# ArgoCD Application for Prometheus Stack Deployment
# Uses kube-prometheus-stack Helm chart for comprehensive monitoring
# This application deploys Prometheus, AlertManager, Node Exporter, and kube-state-metrics
apiVersion: argoproj.io/v1alpha1
kind: Application
metadata:
  name: prometheus
  namespace: argocd
  labels:
    app.kubernetes.io/name: prometheus
    app.kubernetes.io/part-of: monitoring-stack
    app.kubernetes.io/version: "61.6.0"
  finalizers:
    - resources-finalizer.argocd.argoproj.io
spec:
  project: default
  source:
    repoURL: 'https://prometheus-community.github.io/helm-charts'
    chart: kube-prometheus-stack
    targetRevision: 61.6.0
    helm:
      values: |
        # Prometheus configuration
        prometheus:
          prometheusSpec:
            replicas: 2
            storageSpec:
              volumeClaimTemplate:
                spec:
                  storageClassName: standard
                  accessModes: ["ReadWriteOnce"]
                  resources:
                    requests:
                      storage: 20Gi
            resources:
              requests:
                cpu: 200m
                memory: 512Mi
              limits:
                cpu: 500m
                memory: 1Gi
            serviceMonitorSelectorNilUsesHelmValues: false
            ruleSelectorNilUsesHelmValues: false
            retention: "15d"
            retentionSize: "10GiB"
          ingress:
            enabled: true
            ingressClassName: nginx
            annotations:
              cert-manager.io/cluster-issuer: "letsencrypt-prod"
              nginx.ingress.kubernetes.io/ssl-redirect: "true"
              nginx.ingress.kubernetes.io/backend-protocol: "HTTP"
            hosts:
              - prometheus.your-domain.com
            tls:
              - secretName: prometheus-tls
                hosts:
                  - prometheus.your-domain.com

        # Grafana configuration (embedded but will be exposed separately)
        grafana:
          enabled: false  # Disable embedded Grafana as we deploy it separately
          # Note: Standalone Grafana is deployed via applications/monitoring/grafana/application.yaml

        # AlertManager configuration
        alertmanager:
          enabled: true
          alertmanagerSpec:
            replicas: 2
            storage:
              volumeClaimTemplate:
                spec:
                  storageClassName: standard
                  accessModes: ["ReadWriteOnce"]
                  resources:
                    requests:
                      storage: 5Gi
            resources:
              requests:
                cpu: 50m
                memory: 128Mi
              limits:
                cpu: 100m
                memory: 256Mi
          config:
            global:
              resolve_timeout: 5m
              smtp_smarthost: 'localhost:587'
              smtp_from: 'alertmanager@your-domain.com'
            route:
              group_by: ['alertname', 'cluster', 'service']
              group_wait: 30s
              group_interval: 5m
              repeat_interval: 12h
              receiver: 'web.hook'
              routes:
                - match:
                    severity: critical
                  receiver: 'critical-alerts'
                - match:
                    severity: warning
                  receiver: 'warning-alerts'
            receivers:
              - name: 'web.hook'
                webhook_configs:
                  - url: 'http://webhook-receiver:9093/webhook'
              - name: 'critical-alerts'
                webhook_configs:
                  - url: 'http://critical-webhook:9093/critical'
              - name: 'warning-alerts'
                webhook_configs:
                  - url: 'http://warning-webhook:9093/warning'
          ingress:
            enabled: true
            ingressClassName: nginx
            annotations:
              cert-manager.io/cluster-issuer: "letsencrypt-prod"
              nginx.ingress.kubernetes.io/ssl-redirect: "true"
              nginx.ingress.kubernetes.io/backend-protocol: "HTTP"
            hosts:
              - alertmanager.your-domain.com
            tls:
              - secretName: alertmanager-tls
                hosts:
                  - alertmanager.your-domain.com

# Node Exporter
nodeExporter:
  enabled: true
  resources:
    requests:
      cpu: 50m
      memory: 128Mi
    limits:
      cpu: 100m
      memory: 256Mi
  # Disable hostNetwork and hostPort for minikube compatibility
  hostNetwork: false
  hostPort: 9100
  # Use privileged security context for minikube
  securityContext:
    runAsUser: 0
    runAsGroup: 0
    runAsNonRoot: false

# Kube State Metrics
kubeStateMetrics:
  enabled: true
  resources:
    requests:
      cpu: 50m
      memory: 128Mi
    limits:
      cpu: 100m
      memory: 256Mi

# Default ServiceMonitor and PrometheusRule discovery
defaultRules:
  create: true
  rules:
    alertmanager: true
    etcd: true
    configReloaders: true
    general: true
    k8s: true
    kubeApiserverAvailability: true
    kubeApiserverBurnrate: true
    kubeApiserverHistogram: true
    kubeApiserverSlos: true
    kubelet: true
    kubeProxy: true
    kubePrometheusGeneral: true
    kubePrometheusNodeRecording: true
    kubernetesApps: true
    kubernetesResources: true
    kubernetesStorage: true
    kubernetesSystem: true
    kubeScheduler: true
    kubeStateMetrics: true
    network: true
    node: true
    nodeExporterAlerting: true
    nodeExporterRecording: true
    prometheus: true
    prometheusOperator: true

  destination:
    server: https://kubernetes.default.svc
    namespace: monitoring
  syncPolicy:
    automated:
      prune: true
      selfHeal: true
    syncOptions:
      - CreateNamespace=true
      - ApplyOutOfSyncOnly=true
    retry:
      limit: 5
      backoff:
        duration: 5s
        factor: 2
        maxDuration: 3m

